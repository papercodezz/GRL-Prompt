The following figures show the comparative case study of GRL-Prompt and other baseline methods, i.e.,  Random-1, Random-2, CoT, and PromptPG, Pillow, UDR respectively. It is evident that prompts optimized with GRL-Prompt result in more reasonable responses from LLMs compared to other baseline methods. For example, in Figure~\ref{fig:c1}, the generated prompt from GRL-Prompt (marked in blue) provides more instructive guidance for LLMs. Random-1, on the other hand, clearly gives an oversimplified prompt, leading to an undesired response from the LLMs. Similar results can also be found in Random-2, CoT, and PromptPG, Pillow, UDR.
